{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# # # # # # # # # # Konda Pavan Kumar MArket Basket Analysis Project****","metadata":{}},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents</a>\n\n# 2. Import libraries","metadata":{}},{"cell_type":"code","source":"#Basic necessary Libraries\nimport numpy as np\nimport pandas as pd\n\n#Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport altair as alt\nimport plotly.express as px\nfrom wordcloud import WordCloud,STOPWORDS\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\n\n#Apriori libraries \nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents</a>\n\n# 3. Getting the data","metadata":{}},{"cell_type":"code","source":"groceries=pd.read_csv('../input/groceries-dataset/Groceries_dataset.csv')\nprint(f'Groceries_dataset.csv : {groceries.shape}')\ngroceries.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">According to dataset information, it has the following features : \n>* **Member_number:** This is like a customer id given to the customer post purchase transaction\n>* **Date:** This is the date at which purchase/ transaction was made\n>* **itemDescription:** Name of the item which was purchased","metadata":{}},{"cell_type":"code","source":"groceries.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">From the information we can identify that\n>* We don't have any null records in the dataset. BAM !\n>* Date column is an object data type. small bam!","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents</a>\n\n# 4. Pre-processing\n## Renaming column","metadata":{}},{"cell_type":"code","source":"#Renaming the columns to simple words\ngroceries.rename(columns = {'Member_number':'id','itemDescription':'item'}, inplace = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Date information ","metadata":{}},{"cell_type":"code","source":"#Convert the 'Date' column to datetime format\ngroceries['Date']= pd.to_datetime(groceries['Date'])\n \n#Extracting year,month and day\ngroceries['year'] = groceries['Date'].apply(lambda x : x.year)\ngroceries['month'] = groceries['Date'].apply(lambda x : x.month)\ngroceries['day'] = groceries['Date'].apply(lambda x : x.day)\ngroceries['weekday'] = groceries['Date'].apply(lambda x : x.weekday())\n\n#Rearranging the columns\ngroceries=groceries[['id', 'Date','year', 'month', 'day','weekday','item']]\ngroceries.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents</a>\n\n# 5. EDA\n## No. of items sold in 2014 and 2015","metadata":{}},{"cell_type":"code","source":"#Filtering data by year 2014 and 2015  \ndf1=groceries.groupby(['year']).filter(lambda x: (x['year'] == 2014).any())\ndf2=groceries.groupby(['year']).filter(lambda x: (x['year'] == 2015).any())\n\n#Plotting monthly data of number of quantity purchased in 2014 and 2015 \nsales_2014=hv.Bars(df1.groupby(['month'])['item'].count()).opts(ylabel=\"# of items\", title='# of items sold in 2014')\nsales_2015=hv.Bars(df2.groupby(['month'])['item'].count()).opts(ylabel=\"# of items\", title='# of items sold in 2015')\n\n#Merging both plots\n(sales_2014 + sales_2015).opts(opts.Bars(width=380, height=300,tools=['hover'],show_grid=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cummulative day transactions in 2014 & 2015","metadata":{}},{"cell_type":"code","source":"#Plotting day transaction across a typical month in 2014 and 2015\nsales_day=hv.Curve(groceries.groupby(['day'])['item'].count()).opts(ylabel=\"# of items\", title='Cummulative day transactions-2014 & 2015')\n\n#Line chart\nsales_day.opts(opts.Curve(width=800, height=300,tools=['hover'],show_grid=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Monthly quantity purchased from grocery store","metadata":{}},{"cell_type":"code","source":"#Creating temporary data which has quantity purchased column\ntemp=groceries.copy()\ntemp['qty_purchased']=groceries['id'].map(groceries['id'].value_counts())\n\n#Slicing first 5000 rows as altair library can't plot any data which has record beyond that\ntemp1=temp[:5000]\ntemp1.columns\n\n#Plotting\nbrush = alt.selection(type='interval', encodings=['x'])\n\n#Plotting the bar chart\nbars = alt.Chart().mark_bar(color=\"green\").encode(\n    x=alt.X('month(Date):O',title=\"Month\"),\n    y=alt.Y('mean(qty_purchased):Q',title=\"Last Price\"),\n    opacity=alt.condition(brush, alt.OpacityValue(1), alt.OpacityValue(0.7)),\n    tooltip=['month(Date)','mean(qty_purchased)']\n).add_selection(\n    brush\n).properties(height=400,width=600,title=\"Monthly quantity purchased from grocery store-Drag over bars and find average\")\n\n#Plotting avrage line\nline = alt.Chart().mark_rule(color='firebrick').encode(\n    y='mean(qty_purchased):Q',\n    size=alt.SizeValue(3),\n    tooltip=['mean(qty_purchased)']\n).transform_filter(\n    brush\n)\n\n#Display plot using sliced data\nalt.layer(bars, line, data=temp1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of quantity purchased across weekdays","metadata":{}},{"cell_type":"code","source":"#Converting weekday variable to category\ntemp1.weekday = temp1.weekday.astype('category') \n\n#Creating a new dataframe which has the frequency of weekdays\nweekday_bin=temp1['weekday'].value_counts().to_frame().reset_index().rename(columns={'index':'weekday','weekday':'count'})\n\n#Plotting bar chart\nbars = alt.Chart(weekday_bin).mark_bar(color=\"darkorange\").encode(\n    x='weekday',\n    y=alt.Y(\"count\",title='Number of purchases')\n)\n\n#Adding data labels\ntext = bars.mark_text(\n    align='center',\n    baseline='middle',\n    dy=-7 ,\n    size=15,\n).encode(\n    text='count',\n    tooltip=[alt.Tooltip('weekday'),\n            alt.Tooltip('count')]\n)\n\n#Combining both\n(bars + text).properties(\n    width=800,\n    height=400,\n    title=\"Number of quanityt purchases across weekdays\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top and bottom 10 Fast moving products","metadata":{}},{"cell_type":"code","source":"#Setting plot style\nplt.figure(figsize = (15, 8))\nplt.style.use('seaborn-white')\n\n#Top 10 fast moving products\nplt.subplot(1,2,1)\nax=sns.countplot(y=\"item\", hue=\"year\", data=groceries, palette=\"pastel\",\n              order=groceries.item.value_counts().iloc[:10].index)\n\nax.set_xticklabels(ax.get_xticklabels(),fontsize=11,rotation=40, ha=\"right\")\nax.set_title('Top 10 Fast moving products',fontsize= 22)\nax.set_xlabel('Total # of items purchased',fontsize = 20) \nax.set_ylabel('Top 10 items', fontsize = 20)\nplt.tight_layout()\n\n#Bottom 10 fast moving products\nplt.subplot(1,2,2)\nax=sns.countplot(y=\"item\", hue=\"year\", data=groceries, palette=\"pastel\",\n              order=groceries.item.value_counts().iloc[-10:].index)\nax.set_xticklabels(ax.get_xticklabels(),fontsize=11,rotation=40, ha=\"right\")\nax.set_title('Bottom 10 Fast moving products',fontsize= 22)\nax.set_xlabel('Total # of items purchased',fontsize = 20) \nax.set_ylabel('Bottom 10 items', fontsize = 20)\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top Customers in 2014 and 2015","metadata":{}},{"cell_type":"code","source":"#Getting the top customers based on quantity purchased\ntop_customers=temp[['id', 'qty_purchased','year']].sort_values(by = 'qty_purchased',ascending = False).head(500)\n\n#Converting the datatype of id and year\ntop_customers.id = top_customers.id.astype('category') \ntop_customers.year = top_customers.year.astype('category') \n\n#Plotting\nalt.Chart(top_customers).mark_bar(color=\"darkgreen\").encode(\n    x='qty_purchased',\n    y=alt.Y('id', sort='-x'),\n    color='year',\n    tooltip=['id','qty_purchased']\n).properties(height=400,width=600,title=\"Top Customers\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Best Product Wordcloud","metadata":{}},{"cell_type":"code","source":"#Wordcloud\nwordcloud = WordCloud(\n    width = 3000,\n    height = 2000,\n    background_color = 'white').generate(\"\".join(groceries['item']))\nfig = plt.figure(\n    figsize = (50, 30),\n    facecolor = 'k',\n    edgecolor = 'k')\n\n#Display plot\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><b>Insights</b> <br>\n    <li>Milk,Bakery items,vegetables and fruits are the top items from the store</li> \n    <li>There are many varities of furit products like fruit citrus,fruitwhole etc which makes me believe that this store emphasizes in selling fruit and fruit derivative products</li> \n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"## Preparing the data\n> Before proceeding with apriori we have to prepare the data in a sparse matrix format where products are in column and id as index . Initially we group by based on the quantity purchased and later we encode it with 0s and 1s","metadata":{}},{"cell_type":"code","source":"#Creating sparse matrix \nbasket = (temp.groupby(['id', 'item'])['qty_purchased']\n          .sum().unstack().reset_index().fillna(0)\n          .set_index('id'))\n\n#Eoding the quantity urchased\ndef encode(x):\n    '''Encoding the quantity of products with 0s and 1s\n    0:when qty is less than or equal to 0\n    1:when qty is greater than or equal to 1'''\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n    \n#Appying on our data\nbasket_sets = basket.applymap(encode)\nbasket_sets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying Apriori\n> Here we apply apriori algorithm and get all the frequent itemsets(with 70% as support threshold) and apply association rules function to derive rules where we use lift metric ","metadata":{}},{"cell_type":"code","source":"#Apriori- Support70%\nfrequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\n\n#Associaton rules-using lift\nrules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building dynamic function to customize rules","metadata":{}},{"cell_type":"code","source":"#Customizable function to change the lift and confidence\ndef rules_mod(lift,confidence):\n    '''rules_mod is a function to control the rules \n    based on lift and confidence threshold'''\n    return rules[ (rules['lift'] >= lift) &\n      (rules['confidence'] >= confidence) ]\n\n#Calling function\nrules_mod(0.7,0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"#top\" class=\"btn btn-success btn-sm active\" role=\"button\" aria-pressed=\"true\" style=\"color:white;\">Table of Contents</a>\n# 7. Visualizing the results\n> The results in tabular form will not convey much insights into our algorithm so let's visualize the rules\n>\n## Relationship between the metrics","metadata":{}},{"cell_type":"code","source":"#Setting up the style\nplt.figure(figsize = (15, 15))\nplt.style.use('seaborn-white')\n#Plotting the relationship between the metrics\nplt.subplot(221)\nsns.scatterplot(x=\"support\", y=\"confidence\",data=rules)\nplt.subplot(222)\nsns.scatterplot(x=\"support\", y=\"lift\",data=rules)\nplt.subplot(223)\nsns.scatterplot(x=\"confidence\", y=\"lift\",data=rules)\nplt.subplot(224)\nsns.scatterplot(x=\"antecedent support\", y=\"consequent support\",data=rules)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Network diagram of rules\n> Here we make network diagram of specified number of rules where we can see the antecedents and consequents connected to the rules","metadata":{}},{"cell_type":"code","source":"'''a function to build a network diagram connecting antecedents and consequents'''\ndef draw_graph(rules, rules_to_show):\n  import networkx as nx  \n  G1 = nx.DiGraph()\n   \n  color_map=[]\n  N = 50\n  colors = np.random.rand(N)    \n  strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']   \n   \n   \n  for i in range (rules_to_show):      \n    G1.add_nodes_from([\"R\"+str(i)])\n    \n     \n    for a in rules.iloc[i]['antecedents']:\n                \n        G1.add_nodes_from([a])\n        \n        G1.add_edge(a, \"R\"+str(i), color=colors[i] , weight = 2)\n       \n    for c in rules.iloc[i]['consequents']:\n             \n            G1.add_nodes_from([a])\n            \n            G1.add_edge(\"R\"+str(i), c, color=colors[i],  weight=2)\n \n  for node in G1:\n       found_a_string = False\n       for item in strs: \n           if node==item:\n                found_a_string = True\n       if found_a_string:\n            color_map.append('yellow')\n       else:\n            color_map.append('green')       \n \n \n   \n  edges = G1.edges()\n  colors = [G1[u][v]['color'] for u,v in edges]\n  weights = [G1[u][v]['weight'] for u,v in edges]\n \n  pos = nx.spring_layout(G1, k=16, scale=1)\n  nx.draw(G1, pos, edges=edges, node_color = color_map, edge_color=colors, width=weights, font_size=16, with_labels=False)            \n   \n  for p in pos:  # raise text positions\n           pos[p][1] += 0.07\n  nx.draw_networkx_labels(G1, pos)\n  plt.show()\n\n#Calling function with 10 rules\ndraw_graph(rules, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Strength of association using heatmap\n> We have discovered the nassociation of items, what's  good if we don't know the strength of their relationship","metadata":{}},{"cell_type":"code","source":"rules['lhs items'] = rules['antecedents'].apply(lambda x:len(x) )\nrules[rules['lhs items']>1].sort_values('lift', ascending=False).head()\n\n# Replace frozen sets with strings\nrules['antecedents_'] = rules['antecedents'].apply(lambda a: ','.join(list(a)))\nrules['consequents_'] = rules['consequents'].apply(lambda a: ','.join(list(a)))\n\n# Transform the DataFrame of rules into a matrix using the lift metric\npivot = rules[rules['lhs items']>1].pivot(index = 'antecedents_', \n                    columns = 'consequents_', values= 'lift')\n\n\n# Replace frozen sets with strings\nrules['antecedents_'] = rules['antecedents'].apply(lambda a: ','.join(list(a)))\nrules['consequents_'] = rules['consequents'].apply(lambda a: ','.join(list(a)))\n\n# Transform the DataFrame of rules into a matrix using the lift metric\npivot = rules[rules['lhs items']>1].pivot(index = 'antecedents_', \n                    columns = 'consequents_', values= 'lift')\n\n# Generate a heatmap with annotations on and the colorbar off\nsns.heatmap(pivot, annot = True)\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"><div class=\"alert alert-info\" role=\"alert\">\n><ul>\n><b>Insights</b> <br>\n    <li>We have a strong relationship between yogurt,milk and veggies</li> \n    <li>Roll buns are highly correlated with whole milk.</li> \n></ul>\n></div>","metadata":{}},{"cell_type":"markdown","source":"### My other notebooks can be accessed [here](https://www.kaggle.com/benroshan/notebooks)","metadata":{}}]}